{
    "contents" : "###############################################################################\n# ReadDataMart.r\n#   Routines for accessing the Environment Canada real-time hydrometric \n# data mart. There are two main functions: RealTimeHydrometricNetwork() and \n# RetrieveData()  \n#\n# RealTimeHydrometricNetwork:\n#   - args: none required (unless the url/master file path change)\n#   - returns: a data frame of stations available within the data mart\n# RetrieveData:\n#   - args: \n#       1. base url of data mart (../hydrometric)\n#       2. Two (2) character abbreviation of stations province/territory (e.g., \"BC\")\n#       3. Seven (7) character unique station identifier)\n#   - returns: a data frame of data for the last 30 days. Date times in UTC\n###############################################################################\n\n#' RealTimeNetwork\n#' @description Gets the current list of stations available in real-time from the \n#'  National Hydrological Service of Canada.\n#' @param baseURL Base URL to access data mart documentation\n#' @param masterFile File name containing the list of available real-time stations \n#' @seealso \\code{\\link{RealTimeData}}\n#' @export\nRealTimeNetwork <- function(baseURL = \"http://dd.weather.gc.ca/hydrometric/doc/\", masterFile = \"hydrometric_StationList.csv\") {\n  infile <- sprintf(\"%s\\\\%s\", baseURL, masterFile)\n  data <- read.table(infile, sep=\",\", header=TRUE, stringsAsFactors=FALSE)\n  colnames(data) <- c(\"ID\",\"NAME\",\"LATITUDE\",\"LONGITUDE\",\"PROV_TERR\",\"TIMEZONE\")\n  return(data)\n}\n\n#' RealTimeData\n#' @description Gets real-time hydrometric data for a particular hydrometric station\n#'  operated by the National Hydrological Service of Canada.\n#' @param baseURL Base URL to access the data mart\n#' @param provTerr Two-digit provincial or territorial abbreviation based on station location\n#'  (e.g., \"BC\")\n#' @param stationID Seven-digit station identifier\n#' @seealso \\code{\\link{RealTimeNetwork}}  \n#' @export\nRealTimeData <- function(baseURL = \"http://dd.weather.gc.ca/hydrometric/\", provTerr, stationID) {\n  # build URL\n  type <- c(\"hourly\", \"daily\")\n  url <- sprintf(\"%s\\\\csv\\\\%s\\\\%s\", baseURL, provTerr, type)\n  infile <- sprintf(\"%s\\\\%s_%s_%s_hydrometric.csv\", url, provTerr, stationID, type)\n  \n  # define data frame column names - they are not returned\n  # nicely from the data mart files\n  colHeaders <- c(\"ID\",\"DATETIME\",\"HG\",\"HG_GRADE\", \"HG_SYM\", \"HG_CODE\",\"QR\", \"QR_GRADE\",\"QR_SYM\", \"QR_CODE\")\n  \n  # get hourly file\n  h <- try(read.table(infile[1], header=TRUE, sep=\",\", stringsAsFactors=FALSE))\n  print(head(h))\n  if(class(h)==\"try-error\") {\n    stop(sprintf(\"Station [%s] cannot be found within Province/Territory [%s]...url not located %s\",\n                 stationID, provTerr, infile[1]))\n  }\n  colnames(h) <- colHeaders\n  h$DATETIME <- gsub(\"([+-]\\\\d\\\\d)(:)\",\"\\\\1\", h$DATETIME)\n  h$DATETIME <- strptime(h$DATETIME, \"%FT%T%z\", tz=\"UTC\")\n  \n  # get daily file\n  d <- try(read.table(infile[2], header=TRUE, sep=\",\", stringsAsFactors=FALSE))\n  colnames(d) <- colHeaders\n  d$DATETIME <- gsub(\"([+-]\\\\d\\\\d)(:)\",\"\\\\1\", d$DATETIME)\n  d$DATETIME <- strptime(d$DATETIME, \"%FT%T%z\", tz=\"UTC\")\n  \n  # now merge the hourly + daily (hourly data overwrites daily where dates are the same)\n  p <- which(d$DATETIME < min(h$DATETIME))\n  output <- rbind(d[p,], h)\n  return(output)\n}\n\n# test code:\n#network <- RealTimeHydrometricNetwork()\n# library(ggplot2)\n# data <- RetrieveData(provTerr=\"BC\", stationID=\"08MG005\")\n# ggplot(data) + \n#   geom_line(aes(DATETIME, QR), col = \"blue\")\n\n",
    "created" : 1446580369692.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2652429896",
    "id" : "EA5FAF8C",
    "lastKnownWriteTime" : 1432158808,
    "path" : "~/R_LIBRARY/HYDAT/R/ReadDataMart.r",
    "project_path" : "R/ReadDataMart.r",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}